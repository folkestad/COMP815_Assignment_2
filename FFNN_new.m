% Solve a Pattern Recognition Problem with a Neural Network
% Script generated by Neural Pattern Recognition app
% Created Tue Sep 19 10:12:47 NZST 2017
%
% This script assumes these variables are defined:
%
%   X - input data.
%   T - target data.

% Clear Workspace
clear all;

% Load data
load('binaryalphadigs.mat')

% Reshape the input in column format (HOPEFULLY CORRECT)
X = zeros(20*16, 36*39);
pos = 1;
for i = 1:size(dat, 1)
    for j = 1:size(dat, 2)
        pixels = dat{i,j}(:);
        for k = 1:size(pixels)
            X(k, pos) = pixels(k);
        end
        pos = pos + 1;
    end
end

% Create one-hot encoded targets in column format
T = zeros(36, 36*39);
value = 1;
for i = 1:36*39
    T(value, i) = 1;
    if mod(i, 39) == 0
        value = value + 1;
    end
end

% Merge, shuffle and split data + targets
% ALL_DATA = cat(1, X, T);
% SHUFFELED_DATA = ALL_DATA(:, randperm(size(ALL_DATA, 2)));
% SPLIT_DATA = mat2cell(SHUFFELED_DATA, [320, 36], 1404);
% X = cell2mat(SPLIT_DATA(1));
% T = cell2mat(SPLIT_DATA(2));

% Merge, shuffle and split training data + targets
% ALL_DATA = cat(1, trainX, trainY);
% SHUFFELED_DATA = ALL_DATA(:, randperm(size(ALL_DATA, 2)));
% % cols = copy(1404 - test_size);
% SPLIT_DATA = mat2cell(SHUFFELED_DATA, [320, 36], 1368);
% X = cell2mat(SPLIT_DATA(1));
% T = cell2mat(SPLIT_DATA(2));

% Generate new data by flipping random bits
% new_X = X(1:end, 1:end);
% new_T = T(1:end, 1:end);
% for col = 1:size(new_X, 2)
%     for random_bit = 1:2
%         random_bit_index = randi([1, size(new_X, 1)]);
%         new_X(random_bit_index, col) = mod(new_X(random_bit_index, col) + 1, 2);
%     end
% end
% X = horzcat(X, new_X);
% T = horzcat(T, new_T);

% Split into training and test sets
% test_size = 39*1;
% trainX = zeros(320, size(X, 2) - test_size);
% trainY = zeros(36, size(T, 2) - test_size);
% testX = zeros(320, test_size);
% testY = zeros(36, test_size);
% sample_test = 1;
% sample_train = 1;
% for sample = 1:36*39
%     if ismember(mod(sample - 1, 39), [0])
%         for index = 1:320
%             testX(index, sample_test) = X(index, sample);
%         end
%         for index = 1:36
%             testY(index, sample_test) = T(index, sample);
%         end
%         sample_test = sample_test + 1;
%     else
%         for index = 1:320
%             trainX(index, sample_train) = X(index, sample);
%         end
%         for index = 1:36
%             trainY(index, sample_train) = T(index, sample);
%         end
%         sample_train = sample_train + 1;
%     end
%end


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Change variable name
x = X;
t = T;

% Create a Pattern Recognition Network
hiddenLayerSize = 170;
net = patternnet([hiddenLayerSize, hiddenLayerSize]);

% Choose Input and Output Pre/Post-Processing Functions
% For a list of all processing functions type: help nnprocess
net.input.processFcns = {'removeconstantrows','mapminmax'};
net.output.processFcns = {'removeconstantrows','mapminmax'};


% Setup Division of Data for Training, Validation, Testing
% For a list of all data division functions type: help nndivide
net.divideFcn = 'dividerand';  % Divide data randomly
net.divideMode = 'sample';  % Divide up every sample
net.divideParam.trainRatio = 70/100;
net.divideParam.valRatio = 15/100;
net.divideParam.testRatio = 15/100;

% net.divideFcn = 'dividerand';  % Divide data randomly
% net.divideMode = 'sample';  % Divide up every sample
% indexList = 1:size(X, 2);
% disp(mod(indexList, 1) == [1,2]);
% return;
% net.divideParam.trainInd = indexList(find(~(mod(indexList, 39) == 1) & ~(mod(indexList, 39) == 2)));
% net.divideParam.valInd   = indexList(find(mod(indexList, 39) == 2));
% net.divideParam.testInd  = indexList(find(mod(indexList, 39) == 1));

% For help on training function 'trainscg' type: help trainscg
% For a list of all training functions type: help nntrain
net.trainFcn = 'trainscg';  % Scaled conjugate gradient

% Choose a Performance Function
% For a list of all performance functions type: help nnperformance
net.performFcn = 'crossentropy';  % Cross-entropy

% Choose Plot Functions
% For a list of all plot functions type: help nnplot
net.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
  'plotregression', 'plotfit'};


% Train the Network
[net,tr] = train(net,x,t);

% Test the Network on test set
% y = net(testX);
% [~, pred] = max(y);
% [~, true] = max(testY);
% score = sum(true == pred) / length(true);
% disp(score)

% % Other tests
y = net(x);
% [~, pred] = max(y);
% [~, true] = max(t);
% conf_mat = confusionmat(pred, true);
% precision = @(conf_mat) diag(conf_mat)./sum(conf_mat,2);
% recall = @(conf_mat) diag(conf_mat)./sum(conf_mat,1)';
% f1Scores = @(conf_mat) 2*(precision(conf_mat).*recall(conf_mat))./(precision(conf_mat)+recall(conf_mat));
% meanF1 = @(conf_mat) mean(f1Scores(conf_mat));
% disp('Precision');
% dist(precision(conf_mat));
% disp('Recall');
% disp(recall(conf_mat));
% disp('F1Score');
% disp(f1Scores(conf_mat));
% disp('MeanF1\n');
% disp(meanF1(conf_mat));
e = gsubtract(t,y);
tind = vec2ind(t);
yind = vec2ind(y);
percentErrors = sum(tind ~= yind)/numel(tind);
disp(percentErrors)
performance = perform(net,t,y);

% Recalculate Training, Validation and Test Performance
trainTargets = t .* tr.trainMask{1};
valTargets = t  .* tr.valMask{1};
testTargets = t  .* tr.testMask{1};
trainPerformance = perform(net,trainTargets,y);
disp(trainPerformance);
valPerformance = perform(net,valTargets,y);
disp(valPerformance);
testPerformance = perform(net,testTargets,y);
disp(testPerformance);
perf = crossentropy(net,t,y,{1});
disp(perf);
% 
% % View the Network
% view(net)
% % figure, plotperf(tr);

% Plots
% Uncomment these lines to enable various plots.
%figure, plotperform(tr)
%figure, plottrainstate(tr)
%figure, plotconfusion(t,y)
%figure, plotroc(t,y)
%figure, ploterrhist(e)

% Deployment
% Change the (false) values to (true) to enable the following code blocks.
if (false)
  % Generate MATLAB function for neural network for application deployment
  % in MATLAB scripts or with MATLAB Compiler and Builder tools, or simply
  % to examine the calculations your trained neural network performs.
  genFunction(net,'myNeuralNetworkFunction');
  y = myNeuralNetworkFunction(x);
end
if (false)
  % Generate a matrix-only MATLAB function for neural network code
  % generation with MATLAB Coder tools.
  genFunction(net,'myNeuralNetworkFunction','MatrixOnly','yes');
  y = myNeuralNetworkFunction(x);
end
if (false)
  % Generate a Simulink diagram for simulation or deployment with.
  % Simulink Coder tools.
  gensim(net);
end
